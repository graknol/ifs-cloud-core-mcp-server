#!/usr/bin/env python3
"""
Check TensorRT SDK Detection and Usage
"""


def check_tensorrt_sdk():
    """Check if TensorRT SDK is installed and being used."""

    print("üîç Checking TensorRT SDK Installation and Usage")
    print("=" * 55)

    # Check direct TensorRT SDK import
    print("\n1. üîß Direct TensorRT SDK Check:")
    try:
        import tensorrt as trt

        print(f"   ‚úÖ TensorRT SDK installed: version {trt.__version__}")
        print(f"   ‚úÖ TensorRT Builder available: {hasattr(trt, 'Builder')}")
        print(f"   ‚úÖ TensorRT Runtime available: {hasattr(trt, 'Runtime')}")

        # Check TensorRT capabilities
        builder = trt.Builder(trt.Logger(trt.Logger.WARNING))
        print(f"   ‚úÖ TensorRT Builder initialized successfully")

        # Check supported formats and precisions
        print(f"   üìä TensorRT Platform compatibility:")
        print(f"      - GPU compute capability supported: Available")
        print(f"      - FP16 precision: {builder.platform_has_fast_fp16}")
        print(f"      - INT8 precision: {builder.platform_has_fast_int8}")

        tensorrt_sdk_available = True

    except ImportError as e:
        print(f"   ‚ùå TensorRT SDK not found: {e}")
        tensorrt_sdk_available = False
    except Exception as e:
        print(f"   ‚ùå TensorRT SDK error: {e}")
        tensorrt_sdk_available = False

    # Check ONNX Runtime TensorRT provider
    print("\n2. üîß ONNX Runtime TensorRT Provider Check:")
    try:
        import onnxruntime as ort

        providers = ort.get_available_providers()
        print(f"   üìã Available providers: {providers}")

        if "TensorrtExecutionProvider" in providers:
            print("   ‚úÖ TensorrtExecutionProvider available in ONNX Runtime")

            # Get TensorRT provider options
            try:
                provider_options = ort.get_provider_options("TensorrtExecutionProvider")
                print(f"   üìä TensorRT provider options available")
            except:
                print("   ‚ÑπÔ∏è  TensorRT provider options not accessible")
        else:
            print("   ‚ùå TensorrtExecutionProvider not available")

    except ImportError:
        print("   ‚ùå ONNX Runtime not available")

    # Check Optimum integration
    print("\n3. üîß Optimum TensorRT Integration:")
    try:
        from optimum.onnxruntime import ORTModelForSequenceClassification

        print("   ‚úÖ Optimum ONNX Runtime available")

        # Try to check for nvidia-specific optimum modules (may not exist)
        try:
            from optimum.nvidia import TensorRTForSequenceClassification

            print("   ‚úÖ Optimum NVIDIA TensorRT models available")
        except ImportError:
            print("   ‚ÑπÔ∏è  Optimum NVIDIA module not available (normal for Windows)")

    except ImportError:
        print("   ‚ùå Optimum not available")

    # Check current RTX optimizer detection
    print("\n4. üîß RTX 5070 Ti Optimizer Detection:")
    try:
        from rtx5070ti_pytorch_optimizer import (
            TENSORRT_AVAILABLE,
            CUDA_AVAILABLE,
            OPTIMUM_AVAILABLE,
        )

        print(f"   üìä RTX Optimizer Status:")
        print(f"      - TensorRT Available: {'‚úÖ' if TENSORRT_AVAILABLE else '‚ùå'}")
        print(f"      - CUDA Available: {'‚úÖ' if CUDA_AVAILABLE else '‚ùå'}")
        print(f"      - Optimum Available: {'‚úÖ' if OPTIMUM_AVAILABLE else '‚ùå'}")
    except ImportError as e:
        print(f"   ‚ùå RTX Optimizer import failed: {e}")

    # Summary and recommendations
    print(f"\nüìã SUMMARY:")
    print(f"   Direct TensorRT SDK: {'‚úÖ' if tensorrt_sdk_available else '‚ùå'}")
    print(
        f"   ONNX Runtime TensorRT: {'‚úÖ' if 'TensorrtExecutionProvider' in ort.get_available_providers() else '‚ùå'}"
    )

    if tensorrt_sdk_available:
        print(f"\nüî• TENSORRT SDK DETECTED!")
        print(f"   Your RTX 5070 Ti can use the full TensorRT SDK capabilities.")
        print(f"   This provides maximum optimization beyond ONNX Runtime.")
        print(f"   Consider updating the RTX optimizer to use native TensorRT APIs.")
    else:
        print(f"\nüí° RECOMMENDATION:")
        print(f"   If you installed TensorRT SDK, ensure it's in your PATH")
        print(f"   and the Python bindings are properly installed.")


if __name__ == "__main__":
    check_tensorrt_sdk()
